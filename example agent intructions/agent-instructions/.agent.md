# Meta-Instructions for Creating Agent Instructions

<!-- meta:
  topic: meta-instructions
  audience: ai-agent
  model: sonnet-4
  token_budget: medium
  priority: critical
  mode: expert
  read_when: creating any new agent instruction files
  depends_on: []
  last_review: 2025-08-30
-->

These instructions apply only to `jira/docs/llm/agent-instructions` folder

You are working in `docs/llm/agent-instructions` - the meta-layer that defines HOW to create agent
instructions for the Jira frontend codebase. This is the chicken/egg solution: instructions for
writing instructions.

<Governance-Note>

- meta-agent (this file) defines "agent integration" - nuances of top level instructions
- meta-agent (this file) defines how "instructions" `docs/llm/agent-instructions/common/*` should be
  authored
- meta-mode (./modes-guide.md) defines how "modes" `docs/llm/agent-instructions/modes/*` should be
  authored
- derived/governed files should not reference back to meta
- final instruction are expected to be lean and optimized for runtime
- Philosophy, selection rationale, and maintenance rules are expected to be extracted to relative
  meta (meta-agent or meta-mode)

</Governance-Note>

## First-Turn Execution Contract and Generation Rules

> Execute tools FIRST, speak SECOND - prevents "hallucination before verification"

- Instruction-Gate-Protocol is MANDATORY across all generated agent files and MUST appear at the
  very top.
- Response ordering is mechanical: execute `expand_code_chunks(<instruction-file>, [[0, -1]])`
  before emitting any natural language; only after the instruction file is read, respond.
- Single Source of Truth: the Instruction-Gate-Protocol is the only place that mandates
  `expand_code_chunks`. The Quick Decision Tree must reference the gate ("first apply the
  Instruction-Gate-Protocol") and avoid duplicating the reading logic.
- Tone: keep calm and concise. Prefer mechanics over rhetoric. No "TASK FAILURE" or shouting is
  necessary for correct execution.
- Optional runtime guard (recommended if you own the CLI/wrapper): detect task ‚Üí call
  `expand_code_chunks` for the linked instruction file before allowing the first model tokens. This
  ensures ordering even if upstream prompts bias toward ‚Äúexplain-first‚Äù.

<Generator-Checklist>
- [ ] Insert Instruction-Gate-Protocol at the top of generated agent files
- [ ] Ensure Quick Decision Tree references the Gate (no duplicated `expand_code_chunks`)
- [ ] Keep performance/file-pattern guidance as separate sections
- [ ] Route unit-testing requests to unit-testing.md; do not duplicate ‚Äúhow-to‚Äù content elsewhere
- [ ] Keep wording neutral and concise; avoid overemphasis
</Generator-Checklist>

## Agent Modes

<Agent-Modes>

User selects a mode; AI reports confidence. Core stays compact, detailed behavior loaded on demand.

Modes (user selects):

- üöÄ Default: Fast execution, minimal output. Requires üü¢ HIGH or üü° MEDIUM confidence.
  Auto‚Äëescalate if üî¥ LOW.
- üéØ Expert: Quality via 5 phases (UNDERSTAND‚ÜíPLAN‚ÜíIMPLEMENT‚ÜíVERIFY‚ÜíREFINE). Accepts any confidence;
  target HIGH by Verify.
- üë• Pair: Collaborative; explain reasoning; ask questions. Leadership depends on confidence (üü¢ AI
  leads, üü° collaborate, üî¥ user leads).
- üß† Deep Engineer: Deliberate two‚Äëhead divergence (Lite by default). Prefer two subject‚Äëmatter
  expert personas where applicable. Two heads conduct a short cross‚Äëexamination (3 challenges each),
  then synthesize one calibrated plan. Expert‚Äëgrade rigor; early exit if trivial convergence.
- üó≥Ô∏è Council: Five‚Äëjuror extension for extremely consequential decisions. Diverse SME personas
  debate under strict constraints, then vote; moderator synthesizes final plan with verification and
  rollback. Expensive ‚Äî explicit request only.

Confidence (AI reports):

- üü¢ HIGH ‚Äì Clear instruction match, familiar domain, known steps.
- üü° MEDIUM ‚Äì Pattern exists but needs adaptation; partial familiarity.
- üî¥ LOW ‚Äì No clear pattern; unfamiliar domain; no plan.

Auto‚Äëescalation:

- Default + üî¥ LOW ‚Üí Suggest Expert/Pair or request guidance.
- Expert with confidence not improving after research ‚Üí Stop and ask for help or switch to Pair.

On‚Äëdemand mode details (load when selected):

- docs/llm/agent-instructions/modes/default-mode.md
- docs/llm/agent-instructions/modes/expert-mode.md
- docs/llm/agent-instructions/modes/pair-mode.md
- docs/llm/agent-instructions/modes/deep-engineer-mode.md
- docs/llm/agent-instructions/modes/council-mode.md
- docs/llm/agent-instructions/modes/confidence-system.md (ALWAYS load; see Integration with Gate)

Integration with Gate:

- After loading the primary instruction file, also load modes/confidence-system.md.
  - Optimization: If mode is Default and confidence is üü¢ HIGH with tight token budget, you MAY
    defer loading confidence-system.md, but MUST load it immediately when confidence drops to üü°/üî¥
    or on any mode switch.
- Non-Default modes (Expert, Pair, Deep Engineer, Council): MUST load modes/[mode-name]-mode.md
  before proceeding
- Default mode requires no extra loading unless confidence is üü° MEDIUM (then validate) or üî¥ LOW
  (escalate)

</Agent-Modes>

Mode and confidence requirements (for generators):

- Every response MUST include Mode and Confidence, and keep them updated across iterations. When
  confidence changes, explain what made you reconsider and what you now understand differently
- Mode selection precedence: user explicit selection > instruction file meta (`meta: mode:`) > quick
  defaults (Tests‚ÜíPair; Feature-flag cleanup‚ÜíDefault; Complex/risky‚ÜíExpert; Trade-off-heavy‚ÜíDeep
  Engineer; High-stakes‚ÜíCouncil)
- First-turn mode algorithm: (1) read instruction file via Gate; (2) check for user-selected mode;
  (3) else check `meta: mode:`; (4) else apply quick default; (5) if Default and confidence is üî¥
  LOW ‚Üí escalate to Expert or Pair and state why
- Confidence cadence: report at first two iterations and every 3rd iteration thereafter, per Looking
  Back protocol; include a one-sentence problem-focus and instruction-alignment check
- Confidence MUST respond to user feedback: when a user flags issues, gaps, or corrections,
  immediately downgrade confidence and explain the adjustment before proceeding
- When a non-default mode is active, load the corresponding file in
  `docs/llm/agent-instructions/modes/*`; for Default, load on-demand only when confidence is üü°
  MEDIUM (validate) or üî¥ LOW (escalate)
- Confidence-system is the single source of truth for reporting cadence, escalation triggers, and
  evidence requirements. Load it on the first turn; if deferred due to Default+üü¢ HIGH and token
  budget, load immediately on any confidence drop or mode switch

## Semantic Markup Policy (<html>-style tags)

- MUST use XML/HTML-like semantic tags to structure generated agent files. Keep tag names simple,
  lowercase-with-hyphens, and stable.
- MUST ensure tags are balanced and not nested incorrectly. One top-level flow per file.
- PREFERRED top-level tags for entry files (in order):
  - <Instruction-Gate-Protocol>
  - <Instruction-Selection-Process>
  - <Quick-Decision-Tree>
  - <Critical-File-Reading-Requirements>
  - <User-Context>
  - <Performance-Hints>
  - <File-Pattern-Guide>
  - <Search-Optimization>
- ALLOWED: Use Markdown formatting inside tags (bullets, code blocks, inline code), but do not rely
  on Markdown headers for structure.
- RATIONALE: Tags provide clear machine-parseable boundaries, are resilient to formatting changes,
  and reduce ambiguity.

## Eagerness Mitigation and Response Discipline

- First-turn discipline: Execute tools first, speak second. Do not emit natural language before the
  Gate completes.
- Evidence-first pattern: Prefer showing concrete evidence (diffs, file reads, logs) before
  proposing plans or conclusions.
- Minimal narration: Keep first responses tight; narrate only what is necessary to proceed (options,
  confirmations).
- Idempotence: First-turn actions (reading instructions, fetching branch metadata) should be safe to
  repeat.
- Ask-when-ambiguous: If an input (like branch name) is ambiguous or fetch fails, stop and ask for
  clarification instead of guessing.

## Prompt Design Principles (Generator Guidance)

- Deterministic macro: Define a short, deterministic first-turn macro per task family (code review,
  testing, forms). The macro is: detect task ‚Üí expand instruction file ‚Üí perform minimal discovery ‚Üí
  respond.
- Single source of truth: The Gate defines the tool-first behavior. Other sections must reference
  the Gate rather than restating mechanics.
- Calm tone: Avoid overemphasis; be precise and mechanical.
- Memory light: Use ephemeral review context files when needed (e.g.,
  .ai-review/<branch>/review_context.md), but don‚Äôt create heavy state.
- No anthropomorphizing: Avoid ‚ÄúI will think/plan‚Äù; instead: ‚ÄúPer Gate, reading X, fetching Y, then
  options.‚Äù
- CLI guard (optional, recommended): If you own the wrapper, enforce the Gate by triggering
  expand_code_chunks before first tokens are allowed.

<Header-Template-For-Generated-Agent>
# Jira Frontend Development Guide

> Agent workflow guide for Jira frontend development. Ensures proper instruction selection and
> execution patterns.

<!-- derived from docs/llm/agent-instructions/.agent.md -->

<Instruction-Gate-Protocol>
On the first turn (for every task):
- Detect task type using the decision tree (action-based first, domain second)
- Identify the required instruction file(s) for that task
- Execute `expand_code_chunks(<instruction-file>, [[0, -1]])` BEFORE emitting any natural language
- Only after the instruction file is read, respond to the user

Response order rule:

- Never explain a plan or start execution before the instruction gate runs

Error handling:

- If the instruction file cannot be read, ask the user to provide the file path or link and stop

Execution verification ("Looking Back" Protocol):

- After each meaningful change (always first 2 iterations, then every 3rd), verify:
  1. **Problem focus**: Am I still solving what the user asked? (1 sentence)
  2. **Instruction alignment**: Have I loaded and am I following the right instructions?
- If not loaded or misaligned ‚Üí reapply Gate protocol before proceeding
- If stalled (>5 iterations), uncertain, or user challenges approach ‚Üí follow to "STOP and THINK"

Example reflection after each iteration (aka `Status Bar`):

```
[Problem: X] [Mode: Y] [Confidence: üü¢] [Instructions: Y.md loaded ‚úì] [Aligned: ‚úì/‚úó] [Iteration: N/~total]
```

Bootstrap: Modes and Confidence

- Always state Mode and Confidence in the first substantive reply and in each iteration reflection.
  When confidence changes, explain what made you reconsider and what you now understand differently.
  If the user flags an issue or correction, immediately downgrade confidence and explain the
  adjustment before proceeding.
- Respect the instruction's preferred mode (from meta: `mode:`) when available; the user may
  override.
- If using a non-default mode, also load the matching file from
  `docs/llm/agent-instructions/modes/*`.
- Non-Default modes (Expert, Pair, Deep Engineer, Council): MUST load modes/[mode-name]-mode.md
  before proceeding.
- Always load modes/confidence-system.md (may defer only if Default+HIGH confidence with tight token
  budget).
- Confidence: High / Medium / Low. Do not continue in Default mode with Low confidence; escalate
  mode.
- Quick defaults when only this file is available:
  - Tests ‚Üí Pair; Feature-flag cleanup ‚Üí Default; Complex/risky work ‚Üí Expert; Trade-off-heavy ‚Üí
    Deep Engineer; Tie-breaking ‚Üí Council.

Example reflection after each iteration:

```
[Problem: X] [Mode: Y] [Confidence: üü¢] [Instructions: Y.md loaded ‚úì] [Aligned: ‚úì/‚úó] [Iteration: N/~total]
```

</Instruction-Gate-Protocol> </Header-Template-For-Generated-Agent>

### Agent Entry Point Patterns

Choose the appropriate pattern based on Agent:

#### **Specialized Rule Files Pattern** (Recommended for advanced agents)

**Use for**: Cursor

**Structure**: Create individual rule files for each topic with comprehensive descriptions

```markdown
---
description: Comprehensive description of what this rule covers and when to use it
alwaysApply: false
---

# Rule Name

Refer to the following documentation: @docs/llm/agent-instructions/common/topic-name.md
```

**Main entry point** lists available specialized rules:

```markdown
# Jira Frontend Development Guide

This rule provides access to comprehensive Jira frontend development guidelines. For specific
topics, individual rules are now available with detailed descriptions:

## Available Specialized Rules

- **state-management** - Redux patterns, hooks usage, and state handling strategies
- **unit-testing** - Component testing, mocking strategies, and testing patterns
- **integration-testing** - Component integration and end-to-end testing
- **ssr-hydration** - Server-Side Rendering and hydration issue solutions
- **feature-gates** - Feature gate implementation and experiments
- **feature-gate-cleanup** - Removing and cleaning up feature gates
- **entry-points** - Modals, popups, and EntryPoint implementations
- **class-to-functional-conversion** - Converting class to functional components
- **styled-to-css-conversion** - Migrating from styled-components to CSS
- **ramda-to-vanilla-javascript-or-lodash** - Converting Ramda methods to vanilla JavaScript or
  Lodash
- **performance** - Optimization techniques and best practices
- **general-patterns** - Common development patterns and standards
- **team-specific-patterns** - Team-specific workflows and conventions
- **forms** - Atlaskit Forms library, validation patterns, and accessibility
- **handling-errors** - Error boundaries, logging utilities, and analytics reporting
- **typescript-error-suppression-removal** - Removing TypeScript error suppressions and improving
  type safety

Each rule contains focused guidance with improved discoverability through detailed descriptions.
Each instruction may specify a preferred `mode`.
```

#### **Quick Decision Trees Pattern** (Fallback for other agents)

**Bootstrap Requirements for Generated Agent Files:** When generating agent entry files
(`.agent.md`, `copilot-instructions.md`, etc.), include a compact Bootstrap section with Modes and
Confidence primer so agents with only that file can operate:

- State Mode/Confidence in first reply and each iteration
- Honor instruction's preferred `mode:` when available (user may override)
- Load `modes/*` files for non-Default modes
- Confidence escalation rule (Default+LOW ‚Üí Expert/Pair)
- Quick defaults (Tests‚ÜíPair, Feature-flag cleanup‚ÜíDefault, Complex/risky‚ÜíExpert,
  Trade-off-heavy‚ÜíDeep Engineer, Tie-breaking‚ÜíCouncil)

**Use for**: Rovo Dev, GitHub Copilot, Codelassian

CRITICAL: documents linked in the decision tree MUST exist and MUST be discoverable. Ensure agents
will be able to find them.

```markdown
# Jira Frontend Development Guide

<Instruction-Gate-Protocol>
On the first turn (for every task):
- Detect task type using the decision tree (action-based first, domain second)
- Identify the required instruction file(s) for that task
- Execute `expand_code_chunks(<instruction-file>, [[0, -1]])` BEFORE emitting any natural language
- Only after the instruction file is read, respond to the user

Response order rule:

- Never explain a plan or start execution before the instruction gate runs

Error handling:

- If the instruction file cannot be read, ask the user to provide the file path or link and stop
  </Instruction-Gate-Protocol>

<Instruction-Selection-Process>
1. **Parse the request**: What is the user asking me to DO?
2. **Check action-based instructions**: Does this match any action patterns?
3. **Check domain-based instructions**: What technical domains are involved?
4. **Combine appropriately**: Use action instructions as primary, domain as secondary context
</Instruction-Selection-Process>

<Quick-Decision-Tree>

If your task matches below ‚Üí first apply the Instruction-Gate-Protocol to load the linked
instruction file (full-file read), then proceed.

**META-COGNITIVE DECISIONS (When to STOP and THINK, "What Problem We Solve"):**

- **Stalled, uncertain, or user challenges approach?** ‚Üí
  docs/llm/agent-instructions/common/problem-solving-framework.md
- **User ask to "self-reflect"** -> apply
  docs/llm/agent-instructions/common/problem-solving-framework.md to the "current state"

**META-COGNITIVE DECISIONS (When to SWITCH MODES):**

- **Stalled >5 iterations or low confidence in Default?** ‚Üí Expert or Pair
- **Complex trade-offs (performance vs maintainability, multiple valid approaches)?** ‚Üí Deep
  Engineer
- **Multiple valid approaches with conflicting trade-offs requiring tie-breaking?** ‚Üí Council
- **Writing tests with uncertainty?** ‚Üí Pair
- **Need systematic research before implementation?** ‚Üí Expert

**ACTION-BASED DECISIONS (What to DO):**

- **Review a branch?** ‚Üí docs/llm/agent-instructions/common/code-review.md
- **Perform self-review before push?** ‚Üí docs/llm/agent-instructions/common/code-review.md
- **Writing unit tests?** ‚Üí docs/llm/agent-instructions/common/unit-testing.md
- **Writing integration tests?** ‚Üí docs/llm/agent-instructions/common/integration-testing.md
- **Converting class components?** ‚Üí
  docs/llm/agent-instructions/common/class-to-functional-component-conversion.md
- **Converting styled components to CSS?** ‚Üí
  docs/llm/agent-instructions/common/styled-to-compiled-css-conversion.md
- **Converting Ramda methods to vanilla JavaScript or Lodash?** ‚Üí
  docs/llm/agent-instructions/common/ramda-to-vanilla-js-or-lodash-conversion.md
- **Improving useEffects (removing unnecessary effects)?** ‚Üí
  docs/llm/agent-instructions/common/you-might-not-need-use-effect.md
- **Feature flag cleanup?** ‚Üí docs/llm/agent-instructions/common/clean-up-feature-gates.md
- **Stale feature gate?** ‚Üí docs/llm/agent-instructions/common/stale-feature-gates.md
- **Trigger stale-feature-gates agent** ‚Üí docs/llm/agent-instructions/common/stale-feature-gates.md
- **TypeScript error suppression removal?** ‚Üí
  docs/llm/agent-instructions/common/typescript-error-suppression-removal.md
- **Unused i18n message key cleanup?** ‚Üí
  docs/llm/agent-instructions/common/unused-message-key-cleanup.md
- **Changing files at docs/llm/agent-instructions/\*** ‚Üí docs/llm/agent-instructions/.agent.md
- **User asks how you can help?** ‚Üí docs/llm/agent-instructions/common/how-can-i-help.md

**DOMAIN-BASED DECISIONS (What it's ABOUT):**

- **State management question?** ‚Üí docs/llm/agent-instructions/common/state-management.md
- **SSR/hydration issues?** ‚Üí docs/llm/agent-instructions/common/ssr.md
- **Feature flag implementation?** ‚Üí docs/llm/agent-instructions/common/feature-gates-experiments.md
- **Feature reliability analytics?** ‚Üí
  docs/llm/agent-instructions/common/feature-reliability-analytics.md
- **Modals/popups/EntryPoints?** ‚Üí docs/llm/agent-instructions/common/entry-points.md
- **Forms implementation?** ‚Üí docs/llm/agent-instructions/common/forms.md
- **Error handling?** ‚Üí docs/llm/agent-instructions/common/handling-errors.md
- **Performance concerns?** ‚Üí docs/llm/agent-instructions/common/performance.md
- **General patterns:** docs/llm/agent-instructions/common.md
- **Team-specific:** docs/llm/agent-instructions/teams/\*/

**CRITICAL FOR INSTRUCTION FILES**:

- ALWAYS use `expand_code_chunks(file_path, [[0, -1]])` for any `.md` files in
  `docs/llm/agent-instructions/`
- NEVER use `open_files` for instruction files as they may be truncated
- Must see every single line from 0 to -1
- All these files do exists. Having trouble reading content? Ask user to link the file directly.
- Each instruction may specify a preferred `mode`.
- Special requirement: always read `docs/llm/agent-instructions/modes/confidence-system.md` with
  `expand_code_chunks([[0,-1]])` as it governs universal behavior </Quick-Decision-Tree>
```

#### Extra sections (for all agents)

Add the following tips for every agent so they can optimize their runtime. The way this information
is represented should be adapted to the particular agent's capabilities (if known)

##### AI staging area

All temporal files and artefacts should be created at `./.ai-cache/{domain}`. For example
`code review` is located at `./.ai-cache/review/{branch-name}` Agents are welcomed to support
themselves by storing extra memories in this folder.

##### Know your user

**Compliance:** SOX, SOC2, GDPR, CCPA - mandatory security/accessibility gates  
**Constraints:** Established patterns priority, backward compatibility, incremental changes,
architectural review

##### Performance hints

CRITICAL:

- all operation should be performed within "jira" folder
  - **correct**: "search for code in /jira/\*"
  - **incorrect**: "search for code in /confluence/\*"
- all commands should be executed from "jira" folder
  - **correct**: "cd atlassian-frontend-monorepo/jira && yarn dev <command>"
  - **incorrect**: "cd atlassian-frontend-monorepo && yarn dev <command>"
- use `yarn` (or `afm` - which is faster version of yarn)
  - never use `npm`
  - never use `npx`
  - always use only packages already available locally

- information about file patterns so Agent can optimize searches
  - \*.test.tsx ‚Üí unit tests
  - integration-tests/\*_/_.spec.tsx ‚Üí playwright
  - \*.vr.tsx ‚Üí VR
  - \*.examples.tsx ‚Üí Storybook stories
  - feature-tests/\* ‚Üí playwright based "pollinator tests" (separate product)
  - services/\* ‚Üí jira services (separate product)
  - dev-tooling/\* ‚Üí dev tooling (not a part of jira product)
  - platform/_ and postoffice/_ ‚Üí symlinks to separate products (ignore)
  - src/\* ‚Üí Jira production code
- include information about narrowing all searches (unless already operates within a folder or
  workspace)
  - always explicitly exclude `node_modules` from search
  - do search only in `/jira` folder, never perform AFM-wide scans
  - do prefer `/jira/src` or even `/jira/src/packages` or even `/jira/src/packages/{domain}`
- Avoid using `grep` as a bash command, strongly prefer build in **tools** `grep_search` other any
  "terminal" command.
  - Fallback to `git` (`git --no-pager grep/ls-files`) for better performance at scale

No other information should be included in these entry points. They are purely to speedup discovery.

## Core Principle

The result instructions should help hundreds of Jira developers to consistently produce
high-quality, maintainable, and scalable code that aligns with the long-term vision of the Jira
frontend architecture. Instructions should help writing new code and supporting existing. The
outcome should match current reality or be aligned with the future vision. In no circumstances new
patterns should be introduced, the first step is to create instructions that reflect this vision -
support, advice, guide.

- Prioritize Reading over Writing: first action must always be to understand the existing reality of
  the codebase.
- Act as a Guardian of Consistency: - primary goal is to ensure that any new code aligns with
  established, blessed patterns.
- Reduce Hallucination Risk: a strong guardrail against inventing solutions that, while plausible,
  are foreign to your ecosystem.

## North Star Quality Assurance

This document as well as documents created by it should follow a self-review and iterative
improvement process. The goal is to ensure that the instructions are accurate, clear, and useful
before they are finalized.

### Engineering Humility Principle

**Critical Self-Reflection Before Writing:**

- **Assume developer intelligence**: The Jira codebase represents decisions by hundreds of skilled
  engineers over years. If something seems "wrong" or "could be better," first assume you're missing
  context.
- **Seek understanding over invention**: Your role is to document and guide, not to innovate.
  Innovation happened when the patterns were created by domain experts.
- **Pattern archaeology over pattern creation**: Dig deeper to understand WHY existing patterns
  exist before suggesting alternatives.
- **Respect legacy complexity**: What appears as "technical debt" often represents carefully
  considered trade-offs for business requirements you may not see.

**Self-Check Questions:**

- "Am I trying to be clever instead of helpful?"
- "Do I understand the historical context of this decision?"
- "Am I solving problems that don't actually exist?"
- "Have I read actual codebase files before making recommendations?"

### Mandatory Research Protocol

**BEFORE writing any instruction, agents MUST:**

1. **Ensure** operator clearly provided the initial context and scope
2. **Verify** the context is matching requirements of the instruction and can be improved, not
   reinvented
3. **Double check** that claims, ideas, and patterns do match the actual codebase
4. **CRITICAL: Foundation Package Authority** - Examples and patterns must ONLY reference
   authoritative foundation packages (e.g., `@atlaskit/*`, `@atlassian/jira-*` core packages), NEVER
   random usage files from the 10M+ line codebase

**Foundation vs Usage Code Policy:**

- **Foundation Code**: Authoritative packages like `@atlaskit/form`,
  `@atlassian/jira-testing-library` - these define the blessed patterns and are expected to be
  provided in the draft of the instruction
- **Usage Code**: Random files using these packages - these are NOT authoritative examples, they are
  just use cases
- **Rule**: Instructions can only reference own foundation package's documentation
- **Forbidden**: Referencing random usage files like
  `/platform/services/frontkit-dashboard/src/pages/Home/TargetInstancePanel/TargetInstanceModal.tsx`
  as form examples

**Core Packages Declaration Gate (STOP-WORK RULE):**

- Every instruction MUST start with a "Core Packages" block listing the foundation package(s) and
  official doc/source links chosen by the human operator. Include optional Location paths when
  known.
- If the "Core Packages" block is missing or unclear, the agent MUST NOT proceed. Stop and request
  the human operator to name the authoritative package(s) and links.
- Agents are not allowed to infer Core Packages from random usages or popularity; only
  operator-declared Core Packages are valid.

**Why This Matters:**

- Jira has 10M+ lines of code with varying quality and patterns
- One hallucinated instruction can create 100+ incorrect PRs
- Only foundation packages represent the "blessed" patterns developers should follow
- Human operators identify which packages are foundational - trust their guidance

### Mandatory Self-Review Checklist

Before finalizing ANY instruction file, verify:

**North star is set:**

- [ ] Practices and structure described in this document are followed
- [ ] Similar practices and patterns will be applied to the result of produced instructions (by
      induction)
- [ ] Instructions include "Self-Reflection (read first)" section that mirrors this document's
      humility principle

**Agent Instruction Compliance:**

- [ ] Core Packages block lists operator-declared foundation package(s) and official links
- [ ] Examples are minimal and reference-focused
- [ ] Token budget is respected (short: ‚â§800, medium: ‚â§1,600, long: ‚â§3,000)
- [ ] Cross-references exist to related instruction files
- [ ] File follows appropriate template (tactical vs strategic)

**Recursive Quality Enforcement:**

- [ ] Instructions created by following this document will themselves include quality enforcement
      mechanisms
- [ ] Each instruction file includes self-reflection prompts for agents using them
- [ ] Pattern validation requirements are embedded in the instructions themselves

**One size doesn't fit all:**

- if template, patterns or existing structure are not a good fit for the test, adapt
- if this file structure has to be adjusted to accommodate a new topic, mend

## Model Expectations

- Target (only) generation model: Claude Sonnet 4
- Adaptation rules:
  - Keep token-efficient, reference-first guidance; avoid full code dumps
  - Prefer concise sections, tight bullets, explicit links
  - Deeper context is acceptable but still prefer external references over duplication
  - Use plain Markdown; avoid provider-specific syntax or features
  - The primary consumers are AI agents; prioritize their processing efficiency over human visual
    appeal

### Token Budget Policy

- Default token_budget: short
- Budgets (approximate):
  - short: ‚â§800 tokens per file
  - medium: ‚â§1,600 tokens per file
  - long: ‚â§3,000 tokens per file (use sparingly; split when possible)
- Always favor links and references over inline expansion. If a section exceeds its budget, split it
  and add explicit links.

### AI Agent Formatting Efficiency Rules

**Semantic Structure Priority for Agent Instructions:**

- **DO use XML-style tags** like `<State-Management>`, `<Development-Workflow>` for clear semantic
  boundaries in agent instruction files
- **DO maintain hierarchical XML organization** for complex instruction documents
- **DO use XML tags for precise cross-references** and unambiguous section identification
- **DON'T use markdown headers** as primary organizational structure for agent instructions

**Rationale for XML over Markdown in Agent Instructions:**

- XML tags create explicit boundaries that are easier for LLMs to parse and reference
- Enables precise cross-references without ambiguity from spacing or formatting changes
- Provides better hierarchical organization with clear parent-child relationships
- More resilient to document editing and markdown rendering differences
- Maintains consistency with existing patterns in the codebase

**Supporting Markdown Elements:**

- DO use markdown formatting (bold, code blocks, lists) within XML sections for content structure
- DO use semantic structure: Code blocks, bullets provide structural meaning within sections
- DO use plain text emphasis: "CRITICAL:", "NEVER:", "ALWAYS:" for clarity

**Example Structure for Agent Instructions:**

```xml
<Jira-Frontend-Development-Guide>
  <Architecture-Overview>
    Content with **markdown formatting** and `code blocks`
  </Architecture-Overview>
  <Development-Workflow>
    <Package-Development>
      Nested content structure
    </Package-Development>
    <Code-reuse>
      Cross-references to <State-Management> section
    </Code-reuse>
  </Development-Workflow>
</Jira-Frontend-Development-Guide>
```

**Meta-file Exception:**

- This meta-instruction file (.agent.md) maintains Markdown headers for human readability and
  editing
- The XML structure applies to agent instruction files created using these meta-instructions

## File Structure Rules

### Naming Conventions

- **DO**: Use kebab-case for all folders and files (`state-management.md`, `a-b-testing/`)
- **DO**: Use descriptive, domain-specific names (`unit-testing.md` not `test.md`)
- **DO**: Name main feature instructions as `instructions.md`
- **DON'T**: Use camelCase, snake_case, or generic names

### Organization Hierarchy

> Provided as example only

```
docs/llm/agent-instructions/
‚îú‚îÄ‚îÄ .agent.md                    # This meta-instruction file
‚îú‚îÄ‚îÄ README.md                    # Overview and cross-references
‚îú‚îÄ‚îÄ common.md                    # Core shared patterns
‚îú‚îÄ‚îÄ foundation/                  # Foundational patterns for Jira frontend architecture
‚îÇ   ‚îú‚îÄ‚îÄ state-management.md
‚îÇ   ‚îú‚îÄ‚îÄ error-handling.md
‚îÇ   ‚îî‚îÄ‚îÄ performance.md
‚îú‚îÄ‚îÄ implementation/              # Implementation patterns for specific development tasks
‚îÇ   ‚îú‚îÄ‚îÄ unit-testing.md
‚îÇ   ‚îú‚îÄ‚îÄ forms.md
‚îÇ   ‚îú‚îÄ‚îÄ component-design.md
‚îÇ   ‚îî‚îÄ‚îÄ feature-gates.md
‚îú‚îÄ‚îÄ tools/                       # Development tools and automation
‚îÇ   ‚îú‚îÄ‚îÄ testing-tools.md
‚îÇ   ‚îî‚îÄ‚îÄ build-tools.md
‚îÇ   ‚îî‚îÄ‚îÄ migration-patterns.md
‚îî‚îÄ‚îÄ domains/                     # Domain-specific instructions
    ‚îú‚îÄ‚îÄ issues/
    ‚îú‚îÄ‚îÄ projects/
    ‚îî‚îÄ‚îÄ admin/
```

### Cross-Reference System

**DO**: Create intelligent navigation networks that guide LLM decision-making:

- Each instruction file should provide **workflow-aware navigation** not just related topics
- Include **prerequisite reading** - what MUST be understood before starting
- Add **conditional references** - "if implementing X, also consult Y"
- Provide **validation checkpoints** - what to verify after implementation

**Links Section Structure (XML Instruction Files)**:

Use `<Navigation-For-LLM-Agents>` tag instead of generic "related links" sections.

```markdown
<Navigation-For-LLM-Agents>
**Prerequisites** (read BEFORE starting):
- [State Management](./state-management.md) - for data flow decisions
- [Feature Gates](./feature-gates-experiments.md) - ALL changes must be gated

**Workflow Dependencies** (consult DURING implementation):

- [Forms](./forms.md) - when form elements are involved
- [SSR Guidelines](./ssr.md) - when server-side rendering is required

**Validation Checkpoints** (verify AFTER implementation):

- [Unit Testing](./unit-testing.md) - test coverage requirements
- [Integration Testing](./integration-testing.md) - if Storybook examples exist

**Conditional Navigation**:

- IF implementing data fetching ‚Üí [State Management](./state-management.md)
- IF gating UI changes ‚Üí [Feature Gates](./feature-gates-experiments.md)
- IF component has external dependencies ‚Üí [Unit Testing](./unit-testing.md)
- IF prompted to clean up or remove feature gates ‚Üí
  [Clean up Feature Gates](./clean-up-feature-gates.md)

</Navigation-For-LLM-Agents>
```

**Navigation Principles**:

- **Prerequisites**: Critical foundational knowledge needed before proceeding
- **Workflow Dependencies**: Instructions to consult based on implementation decisions
- **Validation Checkpoints**: Post-implementation verification requirements
- **Conditional Navigation**: Context-specific guidance with clear triggers

Allowed during initial development: Create isolated instruction files without cross-references.

### File Relationships

- **DO**: Reference shared patterns from `common/` using relative paths
- **DO**: Use conditional inclusion: `Use [X instructions](./common/X.md) only when...`
- **DON'T**: Duplicate content between files - always reference shared patterns

## Content Structure Rules

### Adaptive Structure by Topic Type

**DO**: Choose structure based on content type:

**For Tactical Topics** (unit-testing, forms, styling):

- Focus on practical patterns and examples
- Show complete working examples when integration is key
- Include common scenarios and variations
- Structure around developer workflows

**For Strategic Topics** (architecture, state-management, performance):

- Apply senior engineering perspective with long-term thinking
- Include architectural trade-offs and decision rationale
- Structure around decision-making frameworks
- Reference existing patterns extensively

**For Domain-Specific Topics** (feature instructions):

- Combine tactical and strategic elements
- Include domain context and constraints
- Show integration with broader Jira architecture

### Standard Markdown Structure

**DEPRECATED (Markdown-first phrasing)**: Previous guidance recommended Markdown headers as the
primary organization. Replaced by XML structural tags for instruction files.

**Tactical Topics Template**:

```markdown
<!-- meta: ... -->

# Topic Name

> Brief description of purpose and scope

<Self-Reflection>
- Assume prior engineers were smart; don't invent new patterns.
- Prefer understanding and documenting existing approaches.
</Self-Reflection>

<Where-To-Find-It>
- Package(s): `@atlassian/package-name` ‚Üí `/jira/src/packages/...`
- Key files: `/jira/src/...:lines`
</Where-To-Find-It>

<Core-Packages>
- Package: `@atlassian/package-name`
- Purpose: What this solves and when should be used
- Key features: Bullet list
</Core-Packages>

<Quick-Reference>
- Key patterns and rules
</Quick-Reference>

<Implementation-Patterns>
  <Common-Scenarios>
  Minimal snippets with file references
  </Common-Scenarios>

  <Advanced-Patterns>
  Complex integration examples by reference
  </Advanced-Patterns>
</Implementation-Patterns>

<Navigation-For-LLM-Agents>
**Prerequisites** (read BEFORE starting):
- [State Management](./state-management.md) - for data flow decisions
- [Feature Gates](./feature-gates-experiments.md) - ALL changes must be gated

**Workflow Dependencies** (consult DURING implementation):

- [Forms](./forms.md) - when form elements are involved
- [SSR Guidelines](./ssr.md) - when server-side rendering is required

**Validation Checkpoints** (verify AFTER implementation):

- [Unit Testing](./unit-testing.md) - test coverage requirements
- [Integration Testing](./integration-testing.md) - if Storybook examples exist

**Conditional Navigation**:

- IF implementing data fetching ‚Üí [State Management](./state-management.md)
- IF gating UI changes ‚Üí [Feature Gates](./feature-gates-experiments.md)
- IF component has external dependencies ‚Üí [Unit Testing](./unit-testing.md)
- IF prompted to clean up or remove feature gates ‚Üí
  [Clean up Feature Gates](./clean-up-feature-gates.md)

</Navigation-For-LLM-Agents>
```

**Strategic Topics Template**:

```markdown
<!-- meta: ... -->

# Topic-Name

> Strategic overview of the domain and decision framework

<Self-Reflection>
- Assume prior engineers were smart; seek context before proposing changes.
</Self-Reflection>

<Where-To-Find-It>
- Package(s): `@atlassian/package-name` ‚Üí `/jira/src/packages/...`
- Key files: `/jira/src/...`
</Where-To-Find-It>

<Design-Philosophy-Rationale>
- The "why" behind the pattern
- Links to decision records (DACI, ADRs in Confluence)
- Strategic trade-offs considered
</Design-Philosophy-Rationale>

<Core-Concepts>
Brief overview of key concepts and their relationships
</Core-Concepts>

<Quick-Decision-Framework>
- Decision checklist or flowchart for common scenarios
</Quick-Decision-Framework>

<Implementation-Patterns>
  <Primary-Approach>
  Recommended patterns for new work
  - Package: `@atlassian/package-name`
  - Purpose: Strategic role in architecture
  </Primary-Approach>

  <Legacy-Alignment>
  How to work with existing patterns
  </Legacy-Alignment>
</Implementation-Patterns>

<Performance-And-Correctness>
- Strategic considerations and trade-offs
</Performance-And-Correctness>

<LLM-Agent-Decision-Matrix>
- Specific guidance for AI agents making decisions
</LLM-Agent-Decision-Matrix>

<Navigation-For-LLM-Agents>
**Prerequisites** (read BEFORE starting):
- [State Management](./state-management.md) - for data flow decisions
- [Feature Gates](./feature-gates-experiments.md) - ALL changes must be gated

**Workflow Dependencies** (consult DURING implementation):

- [Forms](./forms.md) - when form elements are involved
- [SSR Guidelines](./ssr.md) - when server-side rendering is required

**Validation Checkpoints** (verify AFTER implementation):

- [Unit Testing](./unit-testing.md) - test coverage requirements
- [Integration Testing](./integration-testing.md) - if Storybook examples exist

**Conditional Navigation**:

- IF implementing data fetching ‚Üí [State Management](./state-management.md)
- IF gating UI changes ‚Üí [Feature Gates](./feature-gates-experiments.md)
- IF component has external dependencies ‚Üí [Unit Testing](./unit-testing.md)
- IF prompted to clean up or remove feature gates ‚Üí
  [Clean up Feature Gates](./clean-up-feature-gates.md)

</Navigation-For-LLM-Agents>
```

**DON'T**: Force all topics into the same rigid structure

### Required vs Optional Sections

**MUST HAVE** (all files):

- Clear title and purpose
- Implementation guidance
- Related instructions

**ADAPT AS NEEDED**:

- Core Principles (strategic topics)
- Common Pitfalls (when there are genuine gotchas)
- Testing Requirements (when testing strategy matters)

## Code Example Standards

### Foundation Package Authority Policy

**CRITICAL: Examples must ONLY come from authoritative sources:**

- **Authoritative Sources**:
  - are not for the agent to decide. Delegate to the human operator to identify which packages are
    foundational.

- **FORBIDDEN Sources**:
  - Random usage files from the 10M+ line Jira codebase
  - Implementation files that consume packages (these show usage, not blessed patterns)

**Why Foundation Packages Only:**

- Instructions are defining "blessed" patterns that all developers WILL follow, but not all
  developers DID follow
- Usage files may contain outdated, incorrect, or contextual implementations
- One incorrect example can propagate to 100+ PRs through AI code generation
- Only package owners have authority to define correct usage patterns

### Example Placement Strategy

**DO**: Reference authoritative sources only:

- **Package documentation**: Link to official package documentation
- **Use JSDoc references**: Examples belong in the actual code as JSDoc comments
- **Minimal illustrative snippets**: Only show pattern structure, not full implementations

**DON'T**: Reference random codebase usage:

- ‚ùå `/platform/services/a/b/c/UI.tsx`
- ‚ùå Any file outside the foundation package defining the pattern
- ‚ùå Implementation files that happen to use the package
- ‚ùå Files that show "how someone used it" vs "how it should be used"

### Quality Requirements

- **DO**: Reference actual file locations with line numbers
- **DO**: Point to JSDoc documentation in the codebase
- **DO**: Link to Storybook stories for visual examples
- **DO**: Verify all file references exist and are current
- **DON'T**: Duplicate code that exists elsewhere in the codebase

## Content Quality Standards

### Tactics and Strategy Level

**DO**: Write instructions that reflect:

- Strategic long-term thinking to improve product in time
- Solving the task assisting developer today
- Are applicable to a wide range of scenarios and code written in different stages of the product

**DON'T**: Write basic tutorials or simple how-tos

### Technical Accuracy Requirements

**DO**: Before writing any instruction:

1. Require user to provide initial context, do not assume what you don't know
2. Research existing codebase patterns
3. Validate all technical claims against actual code. Instructions must reflect (and improve)
   reality
4. Include specific decision frameworks - Provide clear "when to use what" guidance rather than just
   "how to implement"
5. Reference actual Jira packages and tooling - Every instruction should mention specific
   `@atlassian/*` packages when relevant
6. Link to External Decisions - Encourage the operator to provide links to Confluence (DACI, ADRs)
   to explain the "why" behind major architectural choices (e.g., "why Relay?"). This provides
   deeper context for human developers.

**DON'T**: Make assumptions about technology usage - always verify

### Code Generation Approach

**DO**: Focus on guiding decisions rather than generating code:

- Provide decision trees for choosing between approaches
- Reference existing patterns that developers can adapt
- Include "when to use" guidance for different scenarios
- Link to existing examples rather than creating new ones

**DON'T**: Generate large amounts of boilerplate code in instructions
